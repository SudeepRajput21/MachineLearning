{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Captioning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3ypHyg/TkzvKyDGRNMhl/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "448WUxW-nEqm"
      },
      "source": [
        "!pip3 install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3MEahPduVVY"
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THIPDYzJuYHZ"
      },
      "source": [
        "!mkdir ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aoic4SJzubtA"
      },
      "source": [
        "import json\r\n",
        "token = {\"username\":\"sudeeprajput21\",\"key\":\"1766481fd53783ab03477079054a9b6c\"}\r\n",
        "with open('/content/.kaggle/kaggle.json','w') as file:\r\n",
        "  json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkch2nkYuffH"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lebO6248ujCx",
        "outputId": "b3507c38-6f49-4718-fef5-db48de20ebaf"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGTXN07zunmg"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV2LIIDZuq_J",
        "outputId": "b9307fb1-1773-4ab2-c293-d53dba2ce3df"
      },
      "source": [
        "!kaggle datasets download -d srbhshinde/flickr8k-sau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flickr8k-sau.zip to {/content}/datasets/srbhshinde/flickr8k-sau\n",
            "100% 2.07G/2.08G [00:39<00:00, 43.9MB/s]\n",
            "100% 2.08G/2.08G [00:39<00:00, 56.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWCWVM3TuwRg",
        "outputId": "bd320cb3-f8d8-4228-fe49-1d1086532142"
      },
      "source": [
        "!kaggle datasets download -d yliu9999/glove6b50d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b50d.zip to {/content}/datasets/yliu9999/glove6b50d\n",
            " 96% 65.0M/67.7M [00:02<00:00, 20.2MB/s]\n",
            "100% 67.7M/67.7M [00:02<00:00, 29.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUS5HheDu-RA"
      },
      "source": [
        "!cd /content/{/content}/datasets "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZJTrKFFvIVp",
        "outputId": "60310533-7bf7-40d4-d812-5520af5528a3"
      },
      "source": [
        "!unzip /content/{/content}/datasets/yliu9999/glove6b50d/glove6b50d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/{/content}/datasets/yliu9999/glove6b50d/glove6b50d.zip\n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaOgDUXmwZ_K"
      },
      "source": [
        "!unzip /content/{/content}/datasets/srbhshinde/flickr8k-sau/flickr8k-sau.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KWne2RLwm6P",
        "outputId": "93947df4-5e95-4412-a107-f826d3d202fc"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'{'\u001b[0m/   \u001b[01;34mflickr8k-sau\u001b[0m/   \u001b[01;34mFlickr_Data\u001b[0m/   glove.6B.50d.txt   \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxpAc-vxw0qH",
        "outputId": "61c40a74-9c4d-4a34-fccb-2ac44269d1c3"
      },
      "source": [
        "cd Flickr_Data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Flickr_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY-u7c_-xYN8",
        "outputId": "dfd12dda-a20a-43a4-dd16-d502b6c22e81"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mFlickr_TextData\u001b[0m/  \u001b[01;34mImages\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3HFopf2xcQS",
        "outputId": "2c354fc1-4b7b-4c10-a8da-27e3176b6833"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8tZJrnvxgsk"
      },
      "source": [
        "flickr_path='Flickr_Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN78FfG9xzXL"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import keras\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import string\r\n",
        "import json\r\n",
        "from time import time\r\n",
        "import pickle\r\n",
        "from keras.applications.vgg16 import VGG16\r\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.layers import Input, Dense, Dropout, Embedding,LSTM\r\n",
        "from keras.layers.merge import add\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF9xjvHzzoRO"
      },
      "source": [
        "with open(flickr_path + \"Flickr_TextData/Flickr8k.token.txt\") as filepath:\r\n",
        "  captions = filepath.read()\r\n",
        "  filepath.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gylJumau1kdn"
      },
      "source": [
        "captions = captions.split (\"\\n\") [:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyPwXRPb1w0o"
      },
      "source": [
        "len(captions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foNbpzdV1z52"
      },
      "source": [
        "captions[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaCKl17g13Wp"
      },
      "source": [
        "# Creating a dictionary where key is 'img_name' & value is list of captions \r\n",
        "\r\n",
        "descriptions = {}\r\n",
        "\r\n",
        "for element in captions:\r\n",
        "  img_to_cap = element.split(\"\\t\")\r\n",
        "  img_name = img_to_cap[0].split(\".\")[0]\r\n",
        "  cap = img_to_cap[1]\r\n",
        "\r\n",
        "  if descriptions.get(img_name) == None:\r\n",
        "    descriptions[img_name] = []\r\n",
        "\r\n",
        "  descriptions[img_name].append(cap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t20vXjMC3wAY"
      },
      "source": [
        "descriptions['1000268201_693b08cb0e']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4B0g1nk5FGT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgNKQXo9498F"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcZTxEZ_5DQi"
      },
      "source": [
        "# Lower each word, remove punctuations, remove words lessthan length 1\r\n",
        "\r\n",
        "def clean_text(sample):\r\n",
        "  sample = sample.lower()\r\n",
        "\r\n",
        "  sample = re.sub(\"[^a-z]+\",\" \", sample)\r\n",
        "\r\n",
        "  sample = sample.split()\r\n",
        "\r\n",
        "  sample = [s for s in sample if len(s)>1]\r\n",
        "\r\n",
        "  sample = \" \".join(sample)\r\n",
        "\r\n",
        "  return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv9Mjz1T6nuO"
      },
      "source": [
        "clean_text (\"I am Sudeep 21 03 rAjput @1996\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi-G2M038IWO"
      },
      "source": [
        "# Modify all the captions (cleaned captions)\r\n",
        "\r\n",
        "for key, desc_list in descriptions.items():\r\n",
        "  for i in range (len(desc_list)):\r\n",
        "    desc_list[i] = clean_text(desc_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ydASql8pOj"
      },
      "source": [
        "descriptions ['1000268201_693b08cb0e']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frvGfoqA_0tp"
      },
      "source": [
        "# Writing clean descriptions to .txt file\r\n",
        "\r\n",
        "f = open(\"descriptions.txt\",\"w\")\r\n",
        "f.write(str(descriptions))\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O2tZB8bAaHb"
      },
      "source": [
        "# Reading descriptions file\r\n",
        "\r\n",
        "f = open(\"descriptions.txt\",\"r\")\r\n",
        "descriptions = f.read()\r\n",
        "f.close()\r\n",
        "\r\n",
        "json_acceptable_string = descriptions.replace(\"'\",\"\\\"\")\r\n",
        "descriptions = json.loads(json_acceptable_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uk8gsi7CHjQ"
      },
      "source": [
        "descriptions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPeRxAxGBWpx"
      },
      "source": [
        "# Finding unique vocabulary (finding how many unique words are present in 40K captions)\r\n",
        "\r\n",
        "vocabulary = set()\r\n",
        "\r\n",
        "for key in descriptions.keys():\r\n",
        "  [vocabulary.update(i.split()) for i in descriptions[key]]\r\n",
        "\r\n",
        "print('Vocabulary Size:%d' %len(vocabulary))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4gNI8QqImSr"
      },
      "source": [
        "# Write all words in description dictionary\r\n",
        "\r\n",
        "all_vocab = []\r\n",
        "\r\n",
        "for key in descriptions.keys():\r\n",
        "  [all_vocab.append(i) for des in descriptions[key] for i in des.split()]\r\n",
        "\r\n",
        "print ('Vocabulary Size:%d' %len(all_vocab))\r\n",
        "print (all_vocab[:15])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqzXP22T2hw"
      },
      "source": [
        "# Count the frequency of each word, sort them & discard the words having frequency lesser than the threshold value\r\n",
        "\r\n",
        "import collections\r\n",
        "\r\n",
        "counter = collections.Counter(all_vocab)\r\n",
        "\r\n",
        "dict_ = dict(counter)\r\n",
        "\r\n",
        "threshold_value = 10\r\n",
        "\r\n",
        "sorted_dict = sorted(dict_.items(), reverse = True, key = lambda x: x[1])\r\n",
        "sorted_dict = [x for x in sorted_dict if x[1] > threshold_value]\r\n",
        "all_vocab = [x[0] for x in sorted_dict]\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jz40fN_VPQB",
        "outputId": "faf7924c-6ff2-412a-c012-7edfb225cce4"
      },
      "source": [
        "len(all_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3IW9iRdV6Ht"
      },
      "source": [
        "# Train image file\r\n",
        "\r\n",
        "f = open (flickr_path + \"Flickr_TextData/Flickr_8k.trainImages.txt\")\r\n",
        "train = f.read()\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5msA2mOWYtj"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DccOgWUIWeXT"
      },
      "source": [
        "train = [e.split(\".\")[0] for e in train.split(\"\\n\")[:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp8OBTGZWzRf"
      },
      "source": [
        "# Test image file\r\n",
        "\r\n",
        "f = open (flickr_path + \"Flickr_TextData/Flickr_8k.testImages.txt\")\r\n",
        "test = f.read()\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiMcDc3KXDz0"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrDNd3H2XLcM"
      },
      "source": [
        "test = [e.split(\".\")[0] for e in test.split(\"\\n\")[:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcTK_wN0XUn0"
      },
      "source": [
        "# Create train descriptions dictionary which will be similar to earlier one but having only train samples\r\n",
        "# add startseq + endseq\r\n",
        "\r\n",
        "train_descriptions = {}\r\n",
        "\r\n",
        "for t in train:\r\n",
        "  train_descriptions[t] = []\r\n",
        "\r\n",
        "  for cap in descriptions[t]:\r\n",
        "    cap_to_append = \"startseq \" + cap + \" endseq\"\r\n",
        "    train_descriptions[t].append (cap_to_append)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIuPK54sYeBw"
      },
      "source": [
        "# Mapping descriptions to images\r\n",
        "\r\n",
        "train_descriptions['1000268201_693b08cb0e']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVfUVi5-Y3iE"
      },
      "source": [
        "images = flickr_path = \"Images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuIrtBqCZIb1"
      },
      "source": [
        "**Model for preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtvzpTiZP8w"
      },
      "source": [
        "model = ResNet50(weights=\"imagenet\", input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E9kb7wkaLiI"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj9mz9RQaP5s"
      },
      "source": [
        "# Create a new model by removing the last layer(output layer of 1000 classes) fro resnet50\r\n",
        "\r\n",
        "model_new = Model(model.input, model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCf-SDwtanYs"
      },
      "source": [
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL2YZvzfaxcj"
      },
      "source": [
        "def preprocess_image(img):\r\n",
        "  img = image.load_img(img, target_size=(224,224))\r\n",
        "  img = image.img_to_array(img)\r\n",
        "  img = np.expand_dims(img, axis=0)\r\n",
        "  img = preprocess_input(img)\r\n",
        "  return img\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzear5IP8fxJ"
      },
      "source": [
        "def encode_image(img):\r\n",
        "  img = preprocess_image(img)\r\n",
        "  feature_vector = model_new.predict(img)\r\n",
        "  feature_vector = feature_vector.reshape(feature_vector.shape[1])\r\n",
        "  return feature_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT-m1WuJ-Oq9"
      },
      "source": [
        "# Encoding each image in train set using Resnet\r\n",
        "\r\n",
        "encoding_train = {}\r\n",
        "\r\n",
        "for index, img in enumerate(train):\r\n",
        "\r\n",
        "  img = \"/content/Flickr_Data/Images/{}.jpg\".format(train[index])\r\n",
        "  encoding_train[img[len(images):]] = encode_image(img)\r\n",
        "\r\n",
        "  if index%100==0:\r\n",
        "        print (\"Encoding image-\" + str(index))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUNNKfJpGadq"
      },
      "source": [
        "# Save the train features to disk\r\n",
        "\r\n",
        "with open (\"./encoded_train_images.pkl\", \"wb\") as encoded_pickle:\r\n",
        "   pickle.dump(encoding_train, encoded_pickle)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMQ7E6ENIHoT"
      },
      "source": [
        "# Encoding test images\r\n",
        "\r\n",
        "encoding_test = {}\r\n",
        "\r\n",
        "for index, img in enumerate(test):\r\n",
        "\r\n",
        "  img = \"/content/Flickr_Data/Images/{}.jpg\".format(test[index])\r\n",
        "  encoding_test[img[len(images):]] = encode_image(img)\r\n",
        "\r\n",
        "  if index%100==0:\r\n",
        "        print (\"Encoding image-\" + str(index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFUoAHYIs7d"
      },
      "source": [
        "# Save the bottleneck train features to disk\r\n",
        "\r\n",
        "with open (\"./encoded_test_images.pkl\", \"wb\") as encoded_pickle:\r\n",
        "  pickle.dump(encoding_test, encoded_pickle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF4kFLFzJjn4"
      },
      "source": [
        "# Load the train images features from disk\r\n",
        "\r\n",
        "with open (\"./encoded_train_images.pkl\", \"rb\") as encoded_pickle:\r\n",
        "  encoding_train=pickle.load(encoded_pickle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCtkI-6XJ_Pl"
      },
      "source": [
        "encoding_train['2513260012_03d33305cf.jpg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HatlngydKKGa"
      },
      "source": [
        "# Load the test image features from disk\r\n",
        "\r\n",
        "with open (\"./encoded_test_images.pkl\", \"rb\") as encoded_pickle:\r\n",
        "  encoding_test = pickle.load(encoded_pickle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXKlpRs_KaYX"
      },
      "source": [
        "# word_to_index is mapping between each unique word in all_vocab to int value & index_to_word is vice versa.\r\n",
        "\r\n",
        "index = 1\r\n",
        "word_to_index = {}\r\n",
        "index_to_word = {}\r\n",
        "\r\n",
        "\r\n",
        "for e in all_vocab:\r\n",
        "  word_to_index[e] = index\r\n",
        "  index_to_word[index] = e\r\n",
        "  index+= 1 \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Di-NfcGLZnv"
      },
      "source": [
        "word_to_index ['above']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHtyyAaLegE"
      },
      "source": [
        "index_to_word [225]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKm3Wra1LiCK"
      },
      "source": [
        "len(word_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFIg919KLl49"
      },
      "source": [
        "# Adding startseq & endseq\r\n",
        "\r\n",
        "word_to_index ['startseq'] = 1846\r\n",
        "word_to_index ['endseq'] = 1847\r\n",
        "\r\n",
        "index_to_word [1846] = 'startseq'\r\n",
        "index_to_word [1847] = 'endseq'\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFjEsNorMJ8x"
      },
      "source": [
        "# vocab_size is total vocabulary len +1 because we will append 0's as well\r\n",
        "\r\n",
        "vocab_size = len(index_to_word)+1\r\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rllIoLPhMi5v"
      },
      "source": [
        "all_captions_len = []\r\n",
        "\r\n",
        "for key in train_descriptions.keys():\r\n",
        "    for cap in train_descriptions[key]:\r\n",
        "        all_captions_len.append(len(cap.split()))\r\n",
        "\r\n",
        "max_len = max(all_captions_len)\r\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQR6TS82NGEB"
      },
      "source": [
        "def data_generator (train_descriptions, encoding_train, word_to_index, max_len, num_photos_per_batch):\r\n",
        "\r\n",
        "  x1, x2, y=[], [], []\r\n",
        "  n = 0\r\n",
        "\r\n",
        "  while True:\r\n",
        "\r\n",
        "    for key, desc_list in train_descriptions.items():\r\n",
        "      n += 1\r\n",
        "\r\n",
        "      photo = encoding_train[key+\".jpg\"]\r\n",
        "\r\n",
        "      for desc in desc_list:\r\n",
        "\r\n",
        "        seq = [word_to_index[word] for word in desc.split() if word in word_to_index]\r\n",
        "\r\n",
        "        for i in range(1,len(seq)):\r\n",
        "\r\n",
        "          in_seq = seq[0:i]\r\n",
        "          out_seq = seq[i]\r\n",
        "\r\n",
        "          in_seq = pad_sequences ([in_seq], maxlen = max_len, value = 0, padding = 'post')[0]\r\n",
        "\r\n",
        "          out_seq = to_categorical ([out_seq], num_classes = vocab_size)[0]\r\n",
        "\r\n",
        "          x1.append(photo)\r\n",
        "          x2.append(in_seq)\r\n",
        "          y.append(out_seq)\r\n",
        "\r\n",
        "      if n == num_photos_per_batch:\r\n",
        "        yield [[np.array(x1), np.array(x2)], np.array(y)]\r\n",
        "        x1, x2, y = [], [], []\r\n",
        "        n=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRhIUu_qfAvU"
      },
      "source": [
        "f = open(\"glove.6B.50d.txt\", encoding = 'utf8')\r\n",
        "f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Bf-FrYfa3i"
      },
      "source": [
        "embedding_index = {}\r\n",
        "\r\n",
        "for line in f:\r\n",
        "  values = line.split()\r\n",
        "  word =  values[0]\r\n",
        "  Coefs = np.array(values[1: ], dtype=\"float\")\r\n",
        "\r\n",
        "  embedding_index[word] = Coefs\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fROkFOTaheM5"
      },
      "source": [
        "# Converting words into vector directly - (Embedding Layer Output)\r\n",
        "\r\n",
        "def get_embedding_output():\r\n",
        "  emb_dim = 50\r\n",
        "  embedding_output = np.zeros((vocab_size, emb_dim))\r\n",
        "\r\n",
        "  for word, idx in word_to_index.items():\r\n",
        "    embedding_vector = embedding_index.get(word)\r\n",
        "  \r\n",
        "    if embedding_vector is not None:\r\n",
        "      embedding_output[idx] = embedding_vector\r\n",
        "      \r\n",
        "  return embedding_output\r\n",
        "\r\n",
        "embedding_output = get_embedding_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Caf0eAs_jEEt"
      },
      "source": [
        "embedding_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdVlqbajxLB"
      },
      "source": [
        "embedding_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYrBdXAjkBkJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOJhRc70j03s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldAWQ9F5kMO3"
      },
      "source": [
        "**Defining Model**\r\n",
        "\r\n",
        "Since the input consists of 2 parts, an image vector & partial caption, we cannot use sequential model so we create custom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WknhJEuIkjPA"
      },
      "source": [
        "# Image feature extraction model, inputs image feature vector\r\n",
        "\r\n",
        "input_img_feat = Input(shape=(2048))\r\n",
        "inp_img1 = Dropout(0.3)(input_img_feat)\r\n",
        "inp_img2 = Dense(256, activation='relu')(inp_img1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlbywapAlWef"
      },
      "source": [
        "# Partial caption sequence model, inputs captions\r\n",
        "\r\n",
        "input_cap = Input(shape = max_len)\r\n",
        "inp_cap1 = Embedding(input_dim= vocab_size, output_dim= 50, mask_zero= True)(input_cap)\r\n",
        "inp_cap2 = Dropout(0.3)(inp_cap1)\r\n",
        "inp_cap3 = LSTM(256)(inp_cap2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oys3ZHHRmFTL"
      },
      "source": [
        "decoder1 = add([inp_img2,inp_cap3])\r\n",
        "decoder2 = Dense(256, activation= 'relu')(decoder1)\r\n",
        "outputs = Dense(vocab_size, activation= 'softmax')(decoder2)\r\n",
        "\r\n",
        "# Merge two networks\r\n",
        "model = Model(inputs = [input_img_feat, input_cap], outputs = outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jCemYFFnDJu"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgZ0hbbXnH0f"
      },
      "source": [
        "model.layers[2].set_weights([embedding_output])\r\n",
        "model.layers[2].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeQE3K6pnpBg"
      },
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJlsBFU6n7Uy"
      },
      "source": [
        "epochs = 20\r\n",
        "number_pics_per_batch = 3\r\n",
        "steps = len(train_descriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I1Rt9ByoIyt"
      },
      "source": [
        "for i in range(epochs):\r\n",
        "    generator = data_generator(train_descriptions, encoding_train, word_to_index, max_len, number_pics_per_batch)\r\n",
        "\r\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\r\n",
        "\r\n",
        "    model.save('./model_' + str(i) + '.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRzbFsHoQ_a7"
      },
      "source": [
        "# Taking model from after 19th epoch\r\n",
        "\r\n",
        "model = model(\"./model_19.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDV27udXROBZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4QNVypIRWRZ"
      },
      "source": [
        "def predict_caption(photo):\r\n",
        "  in_text = \"startseq\"\r\n",
        "\r\n",
        "  for i in range(max_len):\r\n",
        "    sequence = [word_to_index[w] for w in in_text.split() if w in word_to_index]\r\n",
        "    sequence = pad_sequences([sequence], maxlen = max_len, padding = 'post')\r\n",
        "\r\n",
        "    ypred = model.predict([photo, sequence])\r\n",
        "    ypred = ypred.argmax()\r\n",
        "    word = index_to_word[ypred]\r\n",
        "    in_text = ' ' + word\r\n",
        "\r\n",
        "    if word = 'endseq':\r\n",
        "      break\r\n",
        "\r\n",
        "   final_caption = in_text.split()\r\n",
        "   final_caption = final_caption[1 :-1]\r\n",
        "   final_caption = ' '.join(final_caption)\r\n",
        "\r\n",
        "   return final_caption"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6gy3piwS71Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sisWhqcjS9_a"
      },
      "source": [
        "for i in range(20):\r\n",
        "  rn = np.random.randint(0, 1000)\r\n",
        "  img_name = list(encoding_test.keys())[rn]\r\n",
        "  photo = encoding_test[img_name].reshape((1, 2048))\r\n",
        "\r\n",
        "  i = plt.imread(images + img_name)\r\n",
        "  plt.imshow(i)\r\n",
        "  plt.axis(\"off\")\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  caption = predict_caption(photo)\r\n",
        "  print(caption)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}